# -*- coding: utf-8 -*-
"""HW4_DMT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qdHn3EGsP0AwixiPC2Co40inHc1LFLka

# Install Library
"""

pip install pyspark -U sentence-transformers

"""# Data Input"""

from google.colab import drive
drive.mount('/content/drive')

"""# Import Library"""

from pyspark.sql.types import ArrayType, StringType, IntegerType, DoubleType, FloatType
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, col
from sentence_transformers import SentenceTransformer
import time
import ast
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LinearSVC, LogisticRegression, RandomForestClassifier
from pyspark.ml.regression import LinearRegression
from pyspark.ml.linalg import Vectors, VectorUDT
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.evaluation import BinaryClassificationEvaluator

train_input_path = '/content/drive/MyDrive/data_dmt/fever-train-kilt.jsonl'
train_output_path = '/content/drive/MyDrive/data_dmt/emb_train.jsonl'

dev_input_path = '/content/drive/MyDrive/data_dmt/fever-dev-kilt.jsonl'
dev_output_path  =  '/content/drive/MyDrive/data_dmt/emb_dev.jsonl'

test_input_path = '/content/drive/MyDrive/data_dmt/fever-test_without_answers-kilt.jsonl'
test_output_path = '/content/drive/MyDrive/data_dmt/emb_test.jsonl'

"""#Part 1

## Part 1.1
"""

spark = SparkSession.builder.appName('Homework3').getOrCreate()

model = SentenceTransformer('paraphrase-distilroberta-base-v1')

def preprocess_data(input_path, output_path):
    df = spark.read.json(input_path)

    if 'output' in df.columns:
        example_udf = udf(lambda output: str([{'anwser': list(output)[0][0]}]), StringType())
        df = df.withColumn('output', example_udf(col('output')))


    embedding_udf = udf(lambda input: model.encode(input).tolist(), ArrayType(FloatType()))
    df = df.withColumn('claim_embedding', embedding_udf(col('input')))

    # write json file
    #df.coalesce(1).write.format('json').save(output_path)

    return df

"""**Train Dataset**"""

# Process dev dataset
train_data = preprocess_data(train_input_path, train_output_path)

train_data.show(5)

train_data.printSchema()

"""**Dev Dataset**"""

# Process dev dataset
dev_data = preprocess_data(dev_input_path, dev_output_path)

"""**Test Dataset**"""

# Process dev dataset
test_data = preprocess_data(test_input_path, test_output_path)

"""## Part 1.2

### Label and vectorize data
"""

def data_processing(data):
    
    if 'output' in data.columns:
        # Label our dataset
        label_udf = udf(lambda output: 1 if ast.literal_eval(output)[0].get('anwser') == "SUPPORTS" else 0, IntegerType())
        data = data.withColumn('label', label_udf(col('output')))

        # Vectorize the claim_embedding
        to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())
        data = data.select(to_vector(col("claim_embedding")).alias("features"), "label")
    else:
        # Vectorize the claim_embedding
        to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())
        data = data.withColumn('claim_embedding', to_vector(col("claim_embedding")))
        data = data.select('id', col("claim_embedding").alias("features"))

    return data

train_df = data_processing(train_data)

train_df.printSchema()

train_df.show()

dev_data = data_processing(dev_data)

test_data = data_processing(test_data)

"""### Imbalancing Class"""

train_df.groupBy('label').count().show()

train_df = train_df.sampleBy("label", fractions={0: 1, 1: 0.373}, seed=0)
train_df.groupBy("label").count().show()

train_df.count()

"""### Modeling

**LogisticRegression**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# lr = LogisticRegression(labelCol='label', featuresCol='features')

paramGrid = (ParamGridBuilder() 
                .addGrid(lr.regParam, [0.01, 0.5]) 
                .addGrid(lr.elasticNetParam, [0, 0.5, 1.0])
                .addGrid(lr.maxIter, [1, 3, 5, 10]) 
                .build())
evaluator = BinaryClassificationEvaluator()
cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator = evaluator, numFolds=3 )

# %%time
cvModel = cv.fit(train_df)

cvModel.save('/content/drive/MyDrive/data_dmt/lr_model2')

from pyspark.ml.tuning import CrossValidatorModel
persistedModel = CrossValidatorModel.load('/content/drive/MyDrive/data_dmt/lr_model2')

### Best Model Parameters
best_model = persistedModel.bestModel

print('Best Param (regParam):', best_model._java_obj.getRegParam())
print('MaxIter:', best_model._java_obj.getMaxIter())
print('elasticNetParam', best_model._java_obj.getElasticNetParam())

from pyspark.mllib.evaluation import MulticlassMetrics

def evaluate_model(model, dev_data):

    ## Evaluate Best Model
    predictions = model.transform(dev_data)

    preds_and_labels = predictions.select(['prediction','label'])

    metrics = MulticlassMetrics(preds_and_labels.rdd.map(lambda x: tuple(map(float, x))))

    cm=metrics.confusionMatrix().toArray()

    print('confustion Matrix', cm)

    print("Accuracy", (cm[0][0]+cm[1][1])/cm.sum())

    print('Precision of REFUTES:', metrics.precision(0))
    print('Precision of SUPPORT:', metrics.precision(1))

    print('Recall of REFUTES:', metrics.recall(0))
    print('Recall of SUPPORT:', metrics.recall(1))

evaluate_model(persistedModel, dev_data)

"""**Predict Test dataset**"""

from pyspark.ml.tuning import CrossValidatorModel
persistedModel = CrossValidatorModel.load('/content/drive/MyDrive/data_dmt/lr_model2')

test_predict = persistedModel.transform(test_data)

test_predict.show()

#  test_predict.coalesce(1).write.format('json').save('/content/drive/MyDrive/data_dmt/lr_tran_prediction.jsonl')

to_output = udf(lambda prediction: [{'answer': "SUPPORTS"}] if prediction == 1 else [{'answer': "REFUTES"}], StringType())
test_predict = test_predict.select('id', to_output(col("prediction")).alias("output"))

test_predict.show()

test_predict.coalesce(1).write.format('json').save('/content/drive/MyDrive/data_dmt/test_set_pred_1.jsonl')

"""**Linear SVM**"""

from pyspark.ml.classification import LinearSVC

lsvc = LinearSVC(labelCol='label', featuresCol='features')

paramGrid = (ParamGridBuilder() 
                .addGrid(lsvc.regParam, [0.01, 0.5])
                .addGrid(lsvc.maxIter, [1,3,5,10]) 
                .build())
evaluator = BinaryClassificationEvaluator()
cv_lsvc = CrossValidator(estimator=lsvc, estimatorParamMaps=paramGrid, evaluator = evaluator, numFolds=3 )

# Commented out IPython magic to ensure Python compatibility.
# %%time
# lsvc_Model = cv_lsvc.fit(train_df)

lsvc_Model.save('/content/drive/MyDrive/data_dmt/lsvc_model_10')

from pyspark.ml.tuning import CrossValidatorModel
persistedModel_lsvc = CrossValidatorModel.load('/content/drive/MyDrive/data_dmt/lsvc_model_10')

### Best Model Parameters
best_model = persistedModel_lsvc.bestModel
print('Best Param (regParam):', best_model._java_obj.getRegParam())
print('MaxIter:', best_model._java_obj.getMaxIter())

## Evaluate Best Model
evaluate_model(persistedModel_lsvc, dev_data)

"""**Predict Test dataset**"""

from pyspark.ml.tuning import CrossValidatorModel
persistedModel_lsvc = CrossValidatorModel.load('/content/drive/MyDrive/data_dmt/lsvc_model_10')

test_predict_lsvc = persistedModel_lsvc.transform(test_data)

test_predict_lsvc.show()

# test_predict_lsvc.coalesce(1).write.format('json').save('/content/drive/MyDrive/data_dmt/lsvc_tran_prediction.jsonl')

to_output = udf(lambda prediction: [{'answer': "SUPPORTS"}] if prediction == 1 else [{'answer': "REFUTES"}], StringType())
test_predict_lsvc = test_predict_lsvc.select('id', to_output(col("prediction")).alias("output"))

test_predict_lsvc.show()

test_predict_lsvc.coalesce(1).write.format('json').save('/content/drive/MyDrive/data_dmt/test_set_pred_2.jsonl')